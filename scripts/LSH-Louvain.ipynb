{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7650849",
   "metadata": {},
   "source": [
    "# 5. LSH-Louvain\n",
    "This notebooks implements a hybrid approach combining LSH and Louvain, so that that tha advantages of each method can be maximized while minimizing their limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2744d2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (10476, 384)\n",
      "Number of games: 10476\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Load precomputed dataframe + embeddings\n",
    "df = pd.read_pickle(\"games_df.pkl\")\n",
    "embeddings = np.load(\"embeddings.npy\")\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"Number of games:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e9de0",
   "metadata": {},
   "source": [
    "## generate random hyperplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "62b972f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.01636433, -0.0822688 , -0.07879106, ..., -0.03037444,\n",
      "         0.02857754,  0.05055213],\n",
      "       [ 0.04226748,  0.01131865, -0.00684458, ..., -0.00090081,\n",
      "        -0.04132469,  0.03906224],\n",
      "       [ 0.00036863, -0.00614149, -0.0029053 , ..., -0.02039806,\n",
      "        -0.06660375, -0.00144424],\n",
      "       ...,\n",
      "       [-0.02160066,  0.00627249,  0.05156927, ...,  0.04815518,\n",
      "         0.03370179, -0.03259623],\n",
      "       [-0.16762874,  0.01323529,  0.035048  , ...,  0.07726289,\n",
      "         0.00270281,  0.01887253],\n",
      "       [ 0.00026104,  0.00025794,  0.05709854, ..., -0.07947919,\n",
      "         0.00487741,  0.00843518]], shape=(16, 384)), array([[ 0.01588397,  0.08047979, -0.00158552, ...,  0.00705402,\n",
      "         0.04997843,  0.02041587],\n",
      "       [ 0.01394603, -0.08109805, -0.02365737, ..., -0.12642717,\n",
      "        -0.02261045,  0.05341474],\n",
      "       [-0.05057007,  0.06450797,  0.05145814, ..., -0.04600032,\n",
      "         0.03888609, -0.01980033],\n",
      "       ...,\n",
      "       [-0.02351672, -0.00966409, -0.03954437, ...,  0.00642898,\n",
      "        -0.00557215,  0.02312812],\n",
      "       [-0.0342959 , -0.10248585,  0.08581795, ..., -0.04368419,\n",
      "         0.00165337,  0.03432107],\n",
      "       [-0.03785464,  0.00130765, -0.04372446, ...,  0.1034576 ,\n",
      "        -0.04797255,  0.01505095]], shape=(16, 384)), array([[-0.0492715 , -0.04882347,  0.05730373, ...,  0.03963514,\n",
      "        -0.03059279, -0.00232954],\n",
      "       [-0.10483974,  0.01314606,  0.00781908, ..., -0.03246192,\n",
      "         0.17929877,  0.04387395],\n",
      "       [-0.02005781, -0.03792807, -0.00023293, ...,  0.06878791,\n",
      "        -0.01334323, -0.02555745],\n",
      "       ...,\n",
      "       [-0.09789081,  0.03996525, -0.02636499, ..., -0.03537205,\n",
      "         0.03891018, -0.03475289],\n",
      "       [-0.04209966,  0.00217943,  0.02296749, ...,  0.03243394,\n",
      "        -0.07258497, -0.02771479],\n",
      "       [-0.01513135,  0.09071861,  0.00834415, ..., -0.01708932,\n",
      "         0.00687753,  0.01409264]], shape=(16, 384)), array([[-0.03999607, -0.04910662, -0.02870632, ...,  0.05434392,\n",
      "        -0.07772539, -0.0025716 ],\n",
      "       [-0.02654287,  0.00277779, -0.02568661, ..., -0.086515  ,\n",
      "        -0.01974546, -0.01931196],\n",
      "       [-0.07667424, -0.04222291, -0.00354963, ...,  0.0650248 ,\n",
      "         0.05287109, -0.00964471],\n",
      "       ...,\n",
      "       [ 0.00495192, -0.08462624,  0.01700768, ...,  0.02397133,\n",
      "        -0.01820782, -0.09293607],\n",
      "       [ 0.01967379,  0.00810949, -0.00010334, ..., -0.04756425,\n",
      "         0.03571145,  0.09634213],\n",
      "       [ 0.01517167,  0.03961845, -0.0633039 , ..., -0.08113675,\n",
      "        -0.08568499, -0.00075574]], shape=(16, 384)), array([[-0.01394949,  0.00204135, -0.000136  , ..., -0.04846347,\n",
      "        -0.04096709,  0.01351781],\n",
      "       [ 0.07961146, -0.10828062,  0.06884617, ..., -0.01778107,\n",
      "         0.0660461 , -0.04683436],\n",
      "       [-0.04775821,  0.04191488,  0.0229981 , ..., -0.01016647,\n",
      "         0.00086298, -0.00254361],\n",
      "       ...,\n",
      "       [ 0.03270245,  0.04010212, -0.00631557, ..., -0.01993291,\n",
      "         0.08478657,  0.00068447],\n",
      "       [-0.00225118,  0.0509911 , -0.04345996, ..., -0.0153045 ,\n",
      "         0.02808485,  0.01566809],\n",
      "       [-0.00839576,  0.01181855, -0.01199758, ...,  0.00784528,\n",
      "        -0.05340276,  0.062887  ]], shape=(16, 384)), array([[ 0.00801481,  0.01827104, -0.06193977, ...,  0.01766061,\n",
      "         0.01108689,  0.03390057],\n",
      "       [-0.09171096, -0.03212645, -0.04725761, ...,  0.07885115,\n",
      "        -0.02964068,  0.0566929 ],\n",
      "       [-0.03670649, -0.0130976 ,  0.09271112, ...,  0.02601321,\n",
      "         0.0430872 ,  0.04115143],\n",
      "       ...,\n",
      "       [-0.03603751,  0.05126393,  0.0871979 , ..., -0.07574168,\n",
      "        -0.01045671,  0.02786202],\n",
      "       [ 0.130081  , -0.16075726,  0.00828366, ..., -0.08746731,\n",
      "         0.00051851,  0.016297  ],\n",
      "       [-0.0329001 , -0.02610592,  0.16876407, ..., -0.05443777,\n",
      "        -0.06354109,  0.02173991]], shape=(16, 384)), array([[ 0.04220077, -0.05940669,  0.02035213, ..., -0.00147758,\n",
      "        -0.10469915,  0.03153633],\n",
      "       [-0.02946258,  0.01887479,  0.02748739, ..., -0.10541544,\n",
      "        -0.01113751, -0.08916498],\n",
      "       [-0.037318  ,  0.00108301, -0.13687808, ...,  0.02720171,\n",
      "         0.08897752, -0.06282407],\n",
      "       ...,\n",
      "       [ 0.09493518,  0.0548783 ,  0.021884  , ..., -0.03640949,\n",
      "        -0.05758794,  0.00788796],\n",
      "       [-0.0294773 ,  0.09224272, -0.03773954, ..., -0.02029764,\n",
      "        -0.0061424 ,  0.02118448],\n",
      "       [ 0.03730545, -0.08485286,  0.00818417, ...,  0.08579059,\n",
      "         0.00821613, -0.06114285]], shape=(16, 384)), array([[ 0.01396224,  0.07134413, -0.04305069, ...,  0.07081833,\n",
      "         0.08135777, -0.00776833],\n",
      "       [-0.12397337, -0.05228136,  0.00065464, ..., -0.07596151,\n",
      "        -0.01938684, -0.03980858],\n",
      "       [-0.02451793, -0.03307227, -0.01671121, ..., -0.03290133,\n",
      "        -0.03503767,  0.06772308],\n",
      "       ...,\n",
      "       [-0.0487902 , -0.07785392, -0.02158487, ..., -0.00125155,\n",
      "         0.07292173, -0.04218128],\n",
      "       [ 0.0074914 ,  0.02092094,  0.04057067, ..., -0.02104067,\n",
      "         0.01139218, -0.00257518],\n",
      "       [ 0.06006763, -0.00161649, -0.09520627, ...,  0.06534055,\n",
      "         0.01098316, -0.04448016]], shape=(16, 384)), array([[-0.02501156,  0.11337555, -0.01773144, ..., -0.0218787 ,\n",
      "        -0.00518444, -0.01590687],\n",
      "       [ 0.02113799,  0.02482576,  0.00725901, ...,  0.0470041 ,\n",
      "         0.00554842,  0.07927728],\n",
      "       [ 0.08000701, -0.04538372,  0.00211974, ...,  0.06263858,\n",
      "         0.11301575,  0.03537713],\n",
      "       ...,\n",
      "       [ 0.03981882, -0.02588911, -0.09647656, ..., -0.0001167 ,\n",
      "         0.07278897, -0.02254792],\n",
      "       [ 0.08214855, -0.00027481,  0.01717788, ..., -0.02282364,\n",
      "        -0.01787648, -0.01453645],\n",
      "       [ 0.01873805, -0.0392105 ,  0.02399589, ..., -0.03513877,\n",
      "        -0.08284116, -0.02294738]], shape=(16, 384)), array([[ 0.02475269, -0.02872579,  0.05416267, ..., -0.00461011,\n",
      "        -0.04578212,  0.07508602],\n",
      "       [ 0.05405599,  0.04603729,  0.05201425, ...,  0.05028646,\n",
      "         0.01874195,  0.00264181],\n",
      "       [ 0.01249395, -0.03768003,  0.0071957 , ...,  0.02164631,\n",
      "        -0.02089581,  0.06413982],\n",
      "       ...,\n",
      "       [ 0.00386461,  0.02488722, -0.00087737, ..., -0.00544108,\n",
      "         0.0239904 ,  0.05215053],\n",
      "       [ 0.00503995,  0.03120779,  0.01071997, ..., -0.01856465,\n",
      "        -0.03452976,  0.07150653],\n",
      "       [ 0.03141522, -0.01312915,  0.08832443, ..., -0.01514497,\n",
      "        -0.04465689, -0.01673623]], shape=(16, 384))]\n"
     ]
    }
   ],
   "source": [
    "def generate_hyperplanes(num_tables, num_planes, dim, seed= 0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    hyperplanes = []\n",
    "    for _ in range(num_tables):\n",
    "        planes = rng.randn(num_planes, dim)\n",
    "        planes /= np.linalg.norm(planes, axis = 1, keepdims = True) +1e-9\n",
    "        hyperplanes.append(planes)\n",
    "    \n",
    "    return hyperplanes\n",
    "\n",
    "# check it\n",
    "dim = embeddings.shape[1]\n",
    "num_tables = 10\n",
    "num_planes = 16\n",
    "\n",
    "hyperplanes = generate_hyperplanes(num_tables, num_planes, dim, seed=33)\n",
    "print(hyperplanes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9724c",
   "metadata": {},
   "source": [
    "## hash each embedding into buckets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "39a87cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_v(v, planes):\n",
    "    projections = planes @ v\n",
    "    bits = projections > 0\n",
    "    key = ''.join('1' if b else '0' for b in bits)\n",
    "    return key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c8709",
   "metadata": {},
   "source": [
    "## Get LSH index, which is tables with buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "16f5b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built LSH tables.\n"
     ]
    }
   ],
   "source": [
    "# Get LSH index, which is tables with buckets\n",
    "\n",
    "def build_lsh_idx(embeddings, hyperplanes):\n",
    "    n, dim = embeddings.shape\n",
    "    num_tables = len(hyperplanes)\n",
    "\n",
    "    tables = [defaultdict(set) for _ in range(num_tables)]\n",
    "\n",
    "    for idx, v in enumerate(embeddings):\n",
    "        for t, planes in enumerate(hyperplanes):\n",
    "            key = hash_v(v, planes)\n",
    "            tables[t][key].add(idx)\n",
    "    \n",
    "    return tables\n",
    "\n",
    "# build it\n",
    "tables = build_lsh_idx(embeddings, hyperplanes)\n",
    "print(\"Built LSH tables.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34804a0",
   "metadata": {},
   "source": [
    "## get candidate neighbours for a game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8592e58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates for game 0: 23\n",
      "Trine 2: Goblin Menace\n",
      "Rake Remastered\n",
      "Total War: Shogun 2 - Fall of the Samurai: The Saga Faction Pack\n",
      "DNF Duel: Season Pass\n",
      "Lords of the Fallen: The Foundation Boost\n",
      "Tri.Defender\n",
      "Injustice 2: Reverse Flash\n",
      "Deep Space Scoundrel\n",
      "Quake III: Team Arena\n",
      "Running into the Cyberpunk\n"
     ]
    }
   ],
   "source": [
    "def lsh_query(idx, embeddings, hyperplanes, tables):\n",
    "    v = embeddings[idx]\n",
    "    candidates = set()\n",
    "\n",
    "    for t, planes in enumerate(hyperplanes):\n",
    "        key = hash_v(v, planes)\n",
    "        bucket = tables[t].get(key, set())\n",
    "        candidates |= bucket\n",
    "\n",
    "    candidates.discard(idx)\n",
    "    return candidates\n",
    "\n",
    "# quick test\n",
    "cand = lsh_query(0, embeddings, hyperplanes, tables)\n",
    "print(\"Candidates for game 0:\", len(cand))\n",
    "for candidate in list(cand)[:10]:\n",
    "    print(df.loc[candidate, 'name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5345e6",
   "metadata": {},
   "source": [
    "## LSH Recommender (from section 3.2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "302e1677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Hunter Hitman\n",
      "Recommendations (cosine_norm, rating, recency, score):\n",
      " --> Running into the Cyberpunk (cos=0.677, rating=1.000, recency = 0.941, score=0.768)\n",
      " --> Scratch Man (cos=0.681, rating=0.923, recency = 0.955, score=0.757)\n",
      " --> Freebooter of Splorr!! (cos=0.654, rating=1.000, recency = 0.919, score=0.750)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(np.int64(10144),\n",
       "  np.float32(0.6766021),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.9410124943999204),\n",
       "  np.float64(0.7677227370574846)),\n",
       " (np.int64(6376),\n",
       "  np.float32(0.6806127),\n",
       "  np.float64(0.9230769231),\n",
       "  np.float64(0.9554482552640748),\n",
       "  np.float64(0.7565890765328211)),\n",
       " (np.int64(9205),\n",
       "  np.float32(0.6544188),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.9187117327890886),\n",
       "  np.float64(0.7499643396302271))]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank candidates by cosine similarity + rating + recency\n",
    "def recommend_lsh_embedding(idx, embeddings, hyperplanes, tables, df, top=5):\n",
    "    v = embeddings[idx]\n",
    "    cand = lsh_query(idx, embeddings, hyperplanes, tables)\n",
    "\n",
    "    if not cand:\n",
    "        print(f\"No candidates for {df.loc[idx, 'name']}\")\n",
    "        return []\n",
    "\n",
    "    cand_indices = np.array(list(cand), dtype=int)\n",
    "\n",
    "    sim = cosine_similarity(\n",
    "        v.reshape(1, -1),\n",
    "        embeddings[cand_indices]\n",
    "    )  # shape: (1, n_candidates)\n",
    "\n",
    "    sim_flat = sim[0]  \n",
    "    cos_norm = (sim_flat + 1.0) / 2.0\n",
    "\n",
    "    ratings = df.loc[cand_indices, 'steam_rating'].astype(float).to_numpy()\n",
    "    recency = df.loc[cand_indices, 'recency'].astype(float).to_numpy()\n",
    "\n",
    "    w_sim = 0.7\n",
    "    w_rating = 0.2\n",
    "    w_date = 0.1\n",
    "\n",
    "    final_score = (w_sim*cos_norm + w_rating*ratings + w_date*recency)\n",
    "    \n",
    "    order = np.argsort(final_score)[::-1]\n",
    "    ordered_indices = cand_indices[order]\n",
    "    ordered_cos_norm = cos_norm[order]    \n",
    "    ordered_rating = ratings[order]\n",
    "    ordered_recency = recency[order]\n",
    "    ordered_score = final_score[order]\n",
    "\n",
    "    results = list(zip(\n",
    "        ordered_indices[:top], \n",
    "        ordered_cos_norm[:top],\n",
    "        ordered_rating[:top],\n",
    "        ordered_recency[:top],\n",
    "        ordered_score[:top]))\n",
    "\n",
    "    print(f\"Query: {df.loc[idx, 'name']}\")\n",
    "    print(\"Recommendations (cosine_norm, rating, recency, score):\")\n",
    "\n",
    "    for j, cos_s, r, rec, score in results:\n",
    "        print(\n",
    "            f\" --> {df.loc[j, 'name']} \"\n",
    "            f\"(cos={cos_s:.3f}, rating={r:.3f}, recency = {rec:.3f}, score={score:.3f})\"\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "# test LSH-only recommender\n",
    "recommend_lsh_embedding(0, embeddings, hyperplanes, tables, df, top=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73edaf92",
   "metadata": {},
   "source": [
    "### Cosine similarity matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "edf5cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity matrix computed in: 0.7867610930006776 sec\n"
     ]
    }
   ],
   "source": [
    "t0_sim = time.perf_counter()\n",
    "sim_matrix = cosine_similarity(embeddings)\n",
    "print(\"Cosine similarity matrix computed in:\", time.perf_counter() - t0_sim, \"sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cb8d2",
   "metadata": {},
   "source": [
    "## Build a similarity graph using LSH candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d48a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSH graph built: nodes=10476, edges=2336\n"
     ]
    }
   ],
   "source": [
    "def build_graph_from_lsh(embeddings, hyperplanes, tables, sim_matrix, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Build an undirected graph:\n",
    "\n",
    "    - Node: game index\n",
    "    - Edge (i, j): if j is in LSH candidates of i and sim_matrix[i, j] >= threshold\n",
    "    - Edge weight: cosine similarity from sim_matrix\n",
    "    \"\"\"\n",
    "    n = embeddings.shape[0]\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(n))\n",
    "\n",
    "    seen_edges = set()  # avoid duplicates\n",
    "\n",
    "    for i in range(n):\n",
    "        cand = list(lsh_query(i, embeddings, hyperplanes, tables))\n",
    "        if not cand:\n",
    "            continue\n",
    "\n",
    "        cand = np.array(cand, dtype=int)\n",
    "\n",
    "        # vectorized: all similarities from row i to its candidates\n",
    "        sims = sim_matrix[i, cand]\n",
    "\n",
    "        # keep only candidates above threshold\n",
    "        mask = sims >= threshold\n",
    "        cand_kept = cand[mask]\n",
    "        sims_kept = sims[mask]\n",
    "\n",
    "        for j, sim_ij in zip(cand_kept, sims_kept):\n",
    "            if j == i:\n",
    "                continue\n",
    "            a, b = (i, j) if i < j else (j, i)\n",
    "            if (a, b) in seen_edges:\n",
    "                continue\n",
    "\n",
    "            G.add_edge(int(a), int(b), weight=float(sim_ij))\n",
    "            seen_edges.add((a, b))\n",
    "\n",
    "    print(\n",
    "        f\"LSH graph built: nodes={G.number_of_nodes()}, \"\n",
    "        f\"edges={G.number_of_edges()}\"\n",
    "    )\n",
    "    return G\n",
    "\n",
    "# example: build graph with some threshold\n",
    "threshold = 0.7\n",
    "G_lsh = build_graph_from_lsh(embeddings, hyperplanes, tables, sim_matrix, threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f61ac",
   "metadata": {},
   "source": [
    "## Evaluate Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dac3926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_louvain(\n",
    "    G: nx.Graph,\n",
    "    embeddings: np.ndarray,\n",
    "    resolution: float = 1.0,\n",
    "    seed: int = 0,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Run Louvain on graph G, compute:\n",
    "    - modularity\n",
    "    - #clusters, cluster sizes\n",
    "    - silhouette, Davies-Bouldin on embeddings\n",
    "    - runtime, peak memory\n",
    "    Returns a dict of metrics.\n",
    "    \"\"\"\n",
    "    # Measure memory + time\n",
    "    tracemalloc.start()\n",
    "    t0_local = time.time()\n",
    "\n",
    "    partition = community_louvain.best_partition(\n",
    "        G,\n",
    "        weight=\"weight\",\n",
    "        resolution=resolution,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    runtime = time.time() - t0_local\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    peak_mb = peak / (1024 ** 2)\n",
    "\n",
    "    labels = np.array([partition[i] for i in range(len(partition))])\n",
    "    n_clusters = len(np.unique(labels))\n",
    "\n",
    "    cluster_sizes = pd.Series(labels).value_counts()\n",
    "    largest_cluster = int(cluster_sizes.max())\n",
    "    smallest_cluster = int(cluster_sizes.min())\n",
    "\n",
    "    modularity = community_louvain.modularity(partition, G, weight=\"weight\")\n",
    "\n",
    "    try:\n",
    "        if n_clusters > 1 and largest_cluster > 1:\n",
    "            db = davies_bouldin_score(embeddings, labels)\n",
    "        else:\n",
    "            db = np.nan\n",
    "    except Exception as e:\n",
    "        print(\"Metric error:\", e)\n",
    "        db = np.nan\n",
    "\n",
    "    return {\n",
    "        \"resolution\": resolution,\n",
    "        \"seed\": seed,\n",
    "        \"n_clusters\": n_clusters,\n",
    "        \"largest_cluster\": largest_cluster,\n",
    "        \"smallest_cluster\": smallest_cluster,\n",
    "        \"modularity\": modularity,\n",
    "        \"davies_bouldin\": db,\n",
    "        \"runtime_sec\": runtime,\n",
    "        \"peak_mem_mb\": peak_mb,\n",
    "    }, partition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69a8c3b",
   "metadata": {},
   "source": [
    "## # Run Louvain on the LSH-derived graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e7d4c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louvain on LSH-graph metrics:\n",
      "resolution: 1.5\n",
      "seed: 0\n",
      "n_clusters: 9448\n",
      "largest_cluster: 82\n",
      "smallest_cluster: 1\n",
      "modularity: 0.8663734158237371\n",
      "davies_bouldin: 0.6354720344927514\n",
      "runtime_sec: 3.4662363529205322\n",
      "peak_mem_mb: 12.988666534423828\n",
      "Saved LSH-Louvain partition and graph.\n"
     ]
    }
   ],
   "source": [
    "resolution = 1.5\n",
    "seed = 0\n",
    "\n",
    "metrics_lsh, partition_lsh = evaluate_louvain(G_lsh, embeddings, resolution=resolution, seed=seed)\n",
    "\n",
    "print(\"Louvain on LSH-graph metrics:\")\n",
    "for k, v in metrics_lsh.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# Save LSH-Louvain partition and graph\n",
    "with open(\"partition_louvain_lsh.pkl\", \"wb\") as f:\n",
    "    pickle.dump(partition_lsh, f)\n",
    "\n",
    "with open(\"graph_louvain_lsh.pkl\", \"wb\") as f:\n",
    "    pickle.dump(G_lsh, f)\n",
    "\n",
    "print(\"Saved LSH-Louvain partition and graph.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73cbc7",
   "metadata": {},
   "source": [
    "## Hybrid LSH + Louvain recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aa79a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lsh_louvain_partition_cache = None\n",
    "\n",
    "def load_lsh_louvain_partition(path=\"partition_louvain_lsh.pkl\"):\n",
    "    global _lsh_louvain_partition_cache\n",
    "    if _lsh_louvain_partition_cache is None:\n",
    "        print(\"Loading LSH-Louvain partition...\")\n",
    "        with open(path, \"rb\") as f:\n",
    "            _lsh_louvain_partition_cache = pickle.load(f)\n",
    "    return _lsh_louvain_partition_cache\n",
    "\n",
    "\n",
    "def recommend_lsh_louvain(idx, embeddings, hyperplanes, tables, df,\n",
    "                          top=10,\n",
    "                          w_sim=0.7, w_rating=0.2, w_date=0.1,\n",
    "                          partition_path=\"partition_louvain_lsh.pkl\"):\n",
    "    \"\"\"\n",
    "    Hybrid LSH + Louvain recommender:\n",
    "\n",
    "    1. LSH gets fast neighbor candidates.\n",
    "    2. Filter candidates to those in the same Louvain community.\n",
    "    3. Rank with combined score of (cosine + rating + recency).\n",
    "    \"\"\"\n",
    "    partition = load_lsh_louvain_partition(partition_path)\n",
    "    cluster_id = partition[idx]\n",
    "\n",
    "    # 1) LSH candidates\n",
    "    cand_all = lsh_query(idx, embeddings, hyperplanes, tables)\n",
    "    if not cand_all:\n",
    "        print(f\"No LSH candidates for {df.loc[idx, 'name']}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"[LSH] Retrieved {len(cand_all)} candidates.\")\n",
    "\n",
    "\n",
    "    # 2) restrict to same Louvain community\n",
    "    cand_filtered = [j for j in cand_all if partition[j] == cluster_id]\n",
    "    print(f\"[Louvain] Candidates in same community: {len(cand_filtered)} \"\n",
    "      f\"(community ID = {cluster_id})\")\n",
    "\n",
    "    if not cand_filtered:\n",
    "        # fallback: if community filter is too strict, use all LSH candidates\n",
    "        print(\"[Fallback] No candidates survived Louvain community filter. \"\n",
    "          \"Using all LSH candidates instead.\")\n",
    "        cand_filtered = list(cand_all)\n",
    "    else:\n",
    "        print(f\"[Hybrid] Using {len(cand_filtered)} hybrid candidates.\")\n",
    "\n",
    "    cand_indices = np.array(cand_filtered, dtype=int)\n",
    "\n",
    "    # 3) compute similarity + rating + recency score\n",
    "    v = embeddings[idx]\n",
    "    sim = cosine_similarity(\n",
    "        v.reshape(1, -1),\n",
    "        embeddings[cand_indices]\n",
    "    )[0]\n",
    "\n",
    "    cos_norm = (sim + 1.0) / 2.0\n",
    "    ratings = df.loc[cand_indices, \"steam_rating\"].astype(float).to_numpy()\n",
    "    recency = df.loc[cand_indices, \"recency\"].astype(float).to_numpy()\n",
    "\n",
    "    final_score = (\n",
    "        w_sim * cos_norm +\n",
    "        w_rating * ratings +\n",
    "        w_date * recency\n",
    "    )\n",
    "\n",
    "    order = np.argsort(final_score)[::-1]\n",
    "    ordered_indices = cand_indices[order]\n",
    "    ordered_cos = cos_norm[order]\n",
    "    ordered_rat = ratings[order]\n",
    "    ordered_rec = recency[order]\n",
    "    ordered_score = final_score[order]\n",
    "\n",
    "    results = list(zip(\n",
    "        ordered_indices[:top],\n",
    "        ordered_cos[:top],\n",
    "        ordered_rat[:top],\n",
    "        ordered_rec[:top],\n",
    "        ordered_score[:top],\n",
    "    ))\n",
    "\n",
    "    print(f\"Query: {df.loc[idx, 'name']}\")\n",
    "    print(\"Recommendations (LSH + Louvain):\")\n",
    "    for j, c, r, rec, s in results:\n",
    "        print(\n",
    "            f\" --> {df.loc[j, 'name']} \"\n",
    "            f\"(cos_norm={c:.3f}, rating={r:.3f}, recency={rec:.3f}, score={s:.3f})\"\n",
    "        )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faa2937",
   "metadata": {},
   "source": [
    "## Test LSH-Louvain recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "30c5c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSH] Retrieved 35 candidates.\n",
      "[Louvain] Candidates in same community: 0 (community ID = 98)\n",
      "[Fallback] No candidates survived Louvain community filter. Using all LSH candidates instead.\n",
      "Query: Master of 4 Swords\n",
      "Recommendations (LSH + Louvain):\n",
      " --> Kannagi Usagi (cos_norm=0.794, rating=0.980, recency=0.961, score=0.848)\n",
      " --> Blade Fury (cos_norm=0.765, rating=0.769, recency=0.955, score=0.785)\n",
      " --> Weaponry (Experimental) (cos_norm=0.713, rating=0.900, recency=0.973, score=0.776)\n",
      " --> Dying Light: Ox Warrior Bundle (cos_norm=0.696, rating=0.963, recency=0.911, score=0.771)\n",
      " --> Break-a-Bot (cos_norm=0.678, rating=0.944, recency=0.989, score=0.763)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(np.int64(9122),\n",
       "  np.float32(0.7944304),\n",
       "  np.float64(0.9804849202),\n",
       "  np.float64(0.9606749962666136),\n",
       "  np.float64(0.8482657462360889)),\n",
       " (np.int64(8267),\n",
       "  np.float32(0.7648356),\n",
       "  np.float64(0.7692307692),\n",
       "  np.float64(0.9552989198068594),\n",
       "  np.float64(0.7847609392380444)),\n",
       " (np.int64(3109),\n",
       "  np.float32(0.71286964),\n",
       "  np.float64(0.9),\n",
       "  np.float64(0.9733187316441834),\n",
       "  np.float64(0.7763406181194813)),\n",
       " (np.int64(293),\n",
       "  np.float32(0.69578016),\n",
       "  np.float64(0.9628975265),\n",
       "  np.float64(0.9111951814425805),\n",
       "  np.float64(0.7707451161929)),\n",
       " (np.int64(2243),\n",
       "  np.float32(0.6782502),\n",
       "  np.float64(0.9444444444000001),\n",
       "  np.float64(0.9885509482801533),\n",
       "  np.float64(0.7625191192251357))]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_lsh_louvain(100, embeddings, hyperplanes, tables, df, top=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
