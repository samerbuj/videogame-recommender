{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c28f30d",
   "metadata": {},
   "source": [
    "LSH with embeddings for a Video Game Recommender\n",
    "\n",
    "This notebook builds a simple LSH index on top of precomputed embeddings and provides a recommendation function\n",
    "\n",
    "It assumes you already have run the Embedding Builder notebook and generated:\n",
    "- games_df.pkl; a DataFrame with game metadata\n",
    "- embeddings.npy; numpy array of shape (n_games, embedding_dim)\n",
    "\n",
    "Steps taken:\n",
    "1. Load the embeddings and game data\n",
    "2. Generate random hyperplanes and build LSH index \n",
    "3. Implement LSH query to get candidate neighbours\n",
    "4. Rank candidates using cosine similarity + rating + recency\n",
    "5. Show example recommendations for a given game index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ac38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the imports and embeddings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# In the original script we used timing/tracemalloc for profiling.\n",
    "# In this notebook we focus on the logic and interactivity, so we skip that.\n",
    "\n",
    "df = pd.read_pickle(\"games_df.pkl\")\n",
    "embeddings = np.load(\"embeddings.npy\")\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"Number of games:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c7c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random hyperplanes\n",
    "# Several sets of random hyperplanes are created, each corresponding to one LSH table, and each hyperplane used to generate one bit of the hash key\n",
    "def generate_hyperplanes(num_tables, num_planes, dim, seed= 0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    hyperplanes = []\n",
    "    for _ in range(num_tables):\n",
    "        planes = rng.randn(num_planes, dim)\n",
    "        planes /= np.linalg.norm(planes, axis = 1, keepdims = True) +1e-9\n",
    "        hyperplanes.append(planes)\n",
    "    \n",
    "    return hyperplanes\n",
    "\n",
    "# check it\n",
    "dim = embeddings.shape[1]\n",
    "num_tables = 10\n",
    "num_planes = 16\n",
    "\n",
    "hyperplanes = generate_hyperplanes(num_tables, num_planes, dim, seed=33)\n",
    "print(hyperplanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835263b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash each embedding into buckets \n",
    "def hash_v(v, planes):\n",
    "    projections = planes @ v\n",
    "    bits = projections > 0\n",
    "    key = ''.join('1' if b else '0' for b in bits)\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LSH index, which is tables with buckets\n",
    "# We build one hash table per hyperplane set. Each table maps a bitstring key to a bucket of game indices whose embedding fall into that region\n",
    "\n",
    "def build_lsh_idx(embeddings, hyperplanes):\n",
    "    n, dim = embeddings.shape\n",
    "    num_tables = len(hyperplanes)\n",
    "\n",
    "    tables = [defaultdict(set) for _ in range(num_tables)]\n",
    "\n",
    "\n",
    "    for idx, v in enumerate(embeddings):\n",
    "        for t, planes in enumerate(hyperplanes):\n",
    "            key = hash_v(v, planes)\n",
    "            tables[t][key].add(idx)\n",
    "    \n",
    "    return tables\n",
    "\n",
    "# check it\n",
    "tables = build_lsh_idx(embeddings, hyperplanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae604a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query LSH; get candidate neighbours for a game\n",
    "# Given a game idx, we compute its hash key in each table, collect all indices in the corresponding bucket, union them into a candidate set\n",
    "def lsh_query(idx, embeddings, hyperplanes, tables):\n",
    "    v = embeddings[idx]\n",
    "    candidates = set()\n",
    "\n",
    "    for t, planes in enumerate(hyperplanes):\n",
    "        key = hash_v(v, planes)\n",
    "        bucket = tables[t].get(key, set())\n",
    "        candidates |= bucket\n",
    "\n",
    "    candidates.discard(idx)\n",
    "    return candidates\n",
    "\n",
    "#test\n",
    "cand = lsh_query(0, embeddings, hyperplanes, tables)\n",
    "print(\"Candidates for game 0:\", cand)\n",
    "for candidate in cand:\n",
    "    print(df.loc[candidate, 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88461b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank candidates by cosine similarity\n",
    "# Using the candidates for a given game, the cosine similarity between the candidates and the game is computed and normalized to [0,1]. \n",
    "# Combining similarity, rating and recency, a final score is obtained for each candidate (0-1) and the results are sorted to print the top recommendations based on this score.\n",
    "# The weights to similarity, rating and recency can be changed to emphasize one or the other. \n",
    "def recommend_lsh_embedding(idx, embeddings, hyperplanes, tables, df, top=5):\n",
    "    v = embeddings[idx]\n",
    "    cand = lsh_query(idx, embeddings, hyperplanes, tables)\n",
    "\n",
    "    if not cand:\n",
    "        print(f\"No candidates for {df.loc[idx, 'name']}\")\n",
    "        return []\n",
    "\n",
    "    cand_indices = np.array(list(cand), dtype=int)\n",
    "\n",
    "    sim = cosine_similarity(\n",
    "        v.reshape(1, -1),\n",
    "        embeddings[cand_indices]\n",
    "    )  # shape: (1, n_candidates)\n",
    "\n",
    "    sim_flat = sim[0]  \n",
    "    cos_norm = (sim_flat + 1.0) / 2.0\n",
    "\n",
    "\n",
    "    ratings = df.loc[cand_indices, 'steam_rating'].astype(float).to_numpy()\n",
    "    recency = df.loc[cand_indices, 'recency'].astype(float).to_numpy()\n",
    "\n",
    "\n",
    "    w_sim = 0.7\n",
    "    w_rating = 0.2\n",
    "    w_date = 0.1\n",
    "\n",
    "    final_score = (w_sim*cos_norm + w_rating*ratings + w_date*recency)\n",
    "    \n",
    "    order = np.argsort(final_score)[::-1]\n",
    "    ordered_indices = cand_indices[order]\n",
    "    ordered_cos_norm = cos_norm[order]    \n",
    "    ordered_rating = ratings[order]\n",
    "    ordered_recency = recency[order]\n",
    "    ordered_score = final_score[order]\n",
    "\n",
    "    results = list(zip(\n",
    "        ordered_indices[:top], \n",
    "        ordered_cos_norm[:top],\n",
    "        ordered_rating[:top],\n",
    "        ordered_recency[:top],\n",
    "        ordered_score[:top]))\n",
    "\n",
    "    print(f\"Query: {df.loc[idx, 'name']}\")\n",
    "    print(\"Recommendations (cosine_norm, rating, recency, score):\")\n",
    "\n",
    "    for j, cos_s, r, rec, score in results:\n",
    "        print(\n",
    "            f\" --> {df.loc[j, 'name']} \"\n",
    "            f\"(cos={cos_s:.3f}, rating={r:.3f}, recency = {rec:.3f}, score={score:.3f})\"\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "#test\n",
    "recommend_lsh_embedding(0, embeddings, hyperplanes, tables, df, top=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
