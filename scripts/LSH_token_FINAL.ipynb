{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c68fbf",
   "metadata": {},
   "source": [
    "LSH with tokens for a Video Game Recommender\n",
    "This notebook implements an LSH-based recommender using token-shingles and MinHash signatures\n",
    "\n",
    "It:\n",
    "1. Loads the raw game dataset\n",
    "2. builds a text field per game\n",
    "3. Creates word shingles\n",
    "4. Computes MinHash signatures \n",
    "5. Builds LSH using banding\n",
    "6. Finds candidate similar games and ranks them using: Jaccard similarity, rating and recency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebac1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary packages\n",
    "import pandas as pd\n",
    "import mmh3\n",
    "from  collections import defaultdict\n",
    "import re\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text from the dataset and build the text to shingle\n",
    "# Normalize the text so that no \"weird\" shingles are formed later\n",
    "df = pd.read_json(\"../data/json/game_overview_final_vol2.json\")\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = text.replace(\";\", \" \")         \n",
    "    text = re.sub(r\"[^a-z0-9\\s]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def make_text(row):\n",
    "    parts =[]\n",
    "\n",
    "    for col in ['name', 'summary', 'genres', 'platforms', 'companies', 'keywords']:\n",
    "        if col in row:\n",
    "            val = row[col]\n",
    "            if isinstance(val, str) and val.strip():\n",
    "                parts.append(val)\n",
    "    \n",
    "    return \" \".join(parts)\n",
    "\n",
    "df['text'] = df.apply(make_text, axis = 1)\n",
    "\n",
    "print(df[[\"game_id\", \"name\", \"text\"]].head())\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a096137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a normalized recency score [0, 1] from the release date\n",
    "df[\"first_release_date\"] = pd.to_datetime(df[\"first_release_date\"], errors=\"coerce\")\n",
    "\n",
    "min_date = df[\"first_release_date\"].min()\n",
    "max_date = df[\"first_release_date\"].max()\n",
    "\n",
    "date_range_days = (max_date - min_date).days\n",
    "\n",
    "def compute_recency(d):\n",
    "    if pd.isna(d):\n",
    "        return 0.5\n",
    "    \n",
    "    return (d - min_date).days/date_range_days\n",
    "df[\"recency\"] = df[\"first_release_date\"].apply(compute_recency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccfa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q - shingles \n",
    "# We turn each game's text into a set of word shingles. These shingles are the input to the MinHash function.\n",
    "def shingle(text: str, q: int = 2):\n",
    "    text = normalize_text(text)\n",
    "    words = text.split()\n",
    "    shingles = set()\n",
    "    for i in range(len(words) - q + 1):\n",
    "        sh = \" \".join(words[i:i+q])\n",
    "        shingles.add(sh)\n",
    "    return shingles\n",
    "\n",
    "NUM_HASHES = 100\n",
    "BANDS = 50\n",
    "ROWS_PER_BAND = 2\n",
    "\n",
    "# Checking it works\n",
    "print(df.loc[1, \"text\"])\n",
    "print(shingle(df.loc[1, \"text\"], q=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a Minhash signature of length \"num_hases\"\n",
    "def minhash_sign(shingles, num_hashes = NUM_HASHES):\n",
    "    signature = []\n",
    "    for seed in range(num_hashes):\n",
    "        min_val = None\n",
    "        for sh in shingles:\n",
    "            h = mmh3.hash(sh, seed, signed=False)\n",
    "            if (min_val is None) or (h < min_val):\n",
    "                min_val = h\n",
    "        signature.append(min_val)\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b493c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the signature for each game\n",
    "def compute_sign(df, q=2, num_hashes = NUM_HASHES):\n",
    "    signatures = {}\n",
    "    shingle_cache = {}\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        shingles = shingle(text, q = q)\n",
    "        shingle_cache[idx] = shingles\n",
    "        sig = minhash_sign(shingles, num_hashes= num_hashes)\n",
    "        signatures[idx] = sig\n",
    "\n",
    "    return signatures, shingle_cache\n",
    "\n",
    "signatures, shingle_cache = compute_sign(df, q= 2, num_hashes= NUM_HASHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f36ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get LSH bands and buckets\n",
    "def build_lsh_idx(signatures, bands=BANDS, row_band=ROWS_PER_BAND):\n",
    "    buckets = defaultdict(set)\n",
    "    for doc_id, sig in signatures.items():\n",
    "        assert len(sig) == bands * row_band\n",
    "        for b in range(bands):\n",
    "            start = b * row_band\n",
    "            end = start + row_band\n",
    "            band_slice = tuple(sig[start:end])\n",
    "            band_hash = hash(band_slice)\n",
    "            buckets[(b, band_hash)].add(doc_id)\n",
    "    return buckets\n",
    "\n",
    "buckets = build_lsh_idx(signatures, bands=BANDS, row_band= ROWS_PER_BAND)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a534eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get candidate neighbours for a game\n",
    "# we first retrieve candidates that share at least one band with the query game\n",
    "def lsh_candidates(doc_id, signatures, buckets, bands=BANDS, row_band=ROWS_PER_BAND):\n",
    "    sig = signatures[doc_id]\n",
    "    candidates = set()\n",
    "    for b in range(bands):\n",
    "        start = b * row_band\n",
    "        end = start + row_band\n",
    "        band_slice = tuple(sig[start:end])\n",
    "        band_hash = hash(band_slice)\n",
    "        bucket_docs = buckets.get((b, band_hash), set())\n",
    "\n",
    "        for other in bucket_docs:\n",
    "            if other != doc_id:\n",
    "                candidates.add(other)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# Check it on one game\n",
    "doc = 0\n",
    "candidates = lsh_candidates(doc, signatures, buckets)\n",
    "print(f\"Candidates for game 0: {candidates}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e057b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the Jaccard Similarity \n",
    "def jaccard_sim(sig1, sig2):\n",
    "    total = sum(1 for a, b in zip(sig1, sig2) if a == b)\n",
    "    return total/len(sig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given game idx:\n",
    "# - Get the candidates\n",
    "# - Compute similarity of signatures\n",
    "# - Filter by a minimum similarity threshold\n",
    "# - Combine similarity, rating and recency into a final score (0-1)\n",
    "# Sort the  final score and print the top results. The weights or threshold can be changed into what wants to be emphasized. \n",
    "def similar_games(doc_id, \n",
    "                  df, \n",
    "                  signatures,\n",
    "                  buckets, \n",
    "                  bands=BANDS, \n",
    "                  row_band=ROWS_PER_BAND, \n",
    "                  thresh = 0.6,\n",
    "                  w_sim = 0.7,\n",
    "                  w_rating = 0.2,\n",
    "                  w_date = 0.1,\n",
    "                  rating_col = 'steam_rating',\n",
    "                  recency_col = 'recency'):\n",
    "    sig0 = signatures[doc_id]\n",
    "    cand = lsh_candidates(doc_id, signatures, buckets, bands, row_band)\n",
    "\n",
    "    results = []\n",
    "    for other in cand:\n",
    "        sim = jaccard_sim(sig0, signatures[other])\n",
    "\n",
    "        if sim < thresh:\n",
    "            continue\n",
    "        \n",
    "        rating = df.loc[other, rating_col]\n",
    "        recency = df.loc[other, recency_col]\n",
    "        \n",
    "        score = (\n",
    "            w_sim*sim + w_rating*rating + w_date*recency\n",
    "        )\n",
    "\n",
    "        results.append((other, sim, rating, recency, score))\n",
    "\n",
    "    results.sort(key=lambda x:x[4], reverse=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "#test it in one case:\n",
    "idx = 0\n",
    "res = similar_games(idx, df, signatures, buckets, bands=BANDS, row_band=ROWS_PER_BAND, thresh=0.2)\n",
    "print(\"Query:\", df.loc[idx, \"name\"])\n",
    "print(\"Found\", len(res), \"similar games\")\n",
    "\n",
    "for other, sim, rating, recency, score in res[:10]:\n",
    "    print(\n",
    "        \" -->\", df.loc[other, \"name\"],\n",
    "        f\"(Jaccard={sim:.2f}, rating={rating:.2f}, recency = {recency:.2f}, score={score:.2f})\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
