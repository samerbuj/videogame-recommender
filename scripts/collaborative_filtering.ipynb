{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ecfeb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f690c91",
   "metadata": {},
   "source": [
    "### Utilities for loading and preparing data\n",
    "\n",
    "In the next cell we define the following utilities functions, that we are going to call through the notebook:\n",
    " \n",
    "- `load_user_game_ratings(path)`: Load `user_games.json` into a pandas DataFrame and keep the columns `user_id`, `game_id`, and `rating`. Returns a cleaned DataFrame.\n",
    "- `encode_ids(df)`: Map original `user_id` and `game_id` values to compact integer indices (0..N-1). Returns the encoded DataFrame with columns `user_idx`, `item_idx`, `rating` plus the mapping dicts: `user_id_to_idx`, `idx_to_user_id`, `game_id_to_idx`, `idx_to_game_id`.\n",
    "- `train_test_split_interactions(df, test_ratio, seed)`: Randomly split interaction rows into train/test arrays. Expects `user_idx`, `item_idx`, `rating` in `df`. Returns `(train, test)` as NumPy arrays.\n",
    "- `load_game_metadata(path)`: Load `game_overview.json` (or similar), convert `first_release_date` from ms-since-epoch to `datetime` if present, and keep a set of useful metadata columns (name, summary, genres, platforms, companies, keywords, steam_rating). Returns a DataFrame of game metadata.\n",
    "\n",
    "Usage: these helpers are used to load interactions, encode ids into compact indices for modeling, split interactions for training/evaluation, and optionally load game metadata for readable recommendation outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f6df5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1. Load and prepare data\n",
    "# =========================\n",
    "\n",
    "def load_user_game_ratings(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load user_games.json into a pandas DataFrame.\n",
    "    Expected keys: user_id, game_id, rating (playtime_hours is ignored here).\n",
    "    \"\"\"\n",
    "    df = pd.read_json(path)\n",
    "    df = df[[\"user_id\", \"game_id\", \"rating\"]].dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_ids(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Map original user_id and game_id to 0..num-1 indices.\n",
    "\n",
    "    Returns:\n",
    "      - df_encoded with columns: user_idx, item_idx, rating\n",
    "      - user_id_to_idx, idx_to_user_id\n",
    "      - game_id_to_idx, idx_to_game_id\n",
    "    \"\"\"\n",
    "    # Sort for reproducibility\n",
    "    user_ids = sorted(df[\"user_id\"].unique())\n",
    "    game_ids = sorted(df[\"game_id\"].unique())\n",
    "\n",
    "    user_id_to_idx: Dict[int, int] = {uid: i for i, uid in enumerate(user_ids)}\n",
    "    idx_to_user_id: Dict[int, int] = {i: uid for uid, i in user_id_to_idx.items()}\n",
    "\n",
    "    game_id_to_idx: Dict[int, int] = {gid: i for i, gid in enumerate(game_ids)}\n",
    "    idx_to_game_id: Dict[int, int] = {i: gid for gid, i in game_id_to_idx.items()}\n",
    "\n",
    "    df_encoded = pd.DataFrame({\n",
    "        \"user_idx\": df[\"user_id\"].map(user_id_to_idx),\n",
    "        \"item_idx\": df[\"game_id\"].map(game_id_to_idx),\n",
    "        \"rating\": df[\"rating\"].astype(float)\n",
    "    })\n",
    "\n",
    "    return df_encoded, user_id_to_idx, idx_to_user_id, game_id_to_idx, idx_to_game_id\n",
    "\n",
    "\n",
    "def train_test_split_interactions(\n",
    "    df: pd.DataFrame,\n",
    "    test_ratio: float = 0.2,\n",
    "    seed: int = 42\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Random train/test split on interactions.\n",
    "    df must have columns: user_idx, item_idx, rating.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    indices = np.arange(len(df))\n",
    "    rng.shuffle(indices)\n",
    "\n",
    "    test_size = int(len(df) * test_ratio)\n",
    "    test_idx = indices[:test_size]\n",
    "    train_idx = indices[test_size:]\n",
    "\n",
    "    train = df.iloc[train_idx].to_numpy()\n",
    "    test = df.iloc[test_idx].to_numpy()\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def load_game_metadata(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load game_overview.json.\n",
    "    Keeps basic metadata and converts release date to datetime.\n",
    "    \"\"\"\n",
    "    games = pd.read_json(path)\n",
    "\n",
    "    # Convert ms-since-epoch to datetime if present\n",
    "    if \"first_release_date\" in games.columns:\n",
    "        games[\"first_release_date\"] = pd.to_datetime(\n",
    "            games[\"first_release_date\"], unit=\"ms\", errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "    keep_cols = [\n",
    "        \"game_id\",\n",
    "        \"name\",\n",
    "        \"summary\",\n",
    "        \"first_release_date\",\n",
    "        \"genres\",\n",
    "        \"platforms\",\n",
    "        \"companies\",\n",
    "        \"keywords\",\n",
    "        \"steam_rating\",\n",
    "    ]\n",
    "    games = games[[c for c in keep_cols if c in games.columns]]\n",
    "\n",
    "    return games\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc381901",
   "metadata": {},
   "source": [
    "### MatrixFactorization class\n",
    "- `MatrixFactorization.__init__(num_users, num_items, n_factors, lr, reg, n_epochs, seed)`: Initializes latent factor matrices `P` and `Q`, user/item biases and training hyperparameters.\n",
    "- `fit(train_data, verbose)`: Trains the model with SGD on (user_idx, item_idx, rating) rows, updating biases and latent factors; prints per-epoch RMSE if `verbose`.\n",
    "- `predict_single(user_idx, item_idx)`: Returns predicted rating for one user-item pair using global mean, biases and dot(P[u], Q[i]).\n",
    "- `predict_batch(data)`: Vectorized loop that returns predictions for an array of triplets (rating column ignored).\n",
    "- `recommend_for_user(user_idx, known_item_indices, top_n)`: Scores all unseen items for `user_idx`, excludes `known_item_indices`, and returns the top-N (item_idx, score) pairs.\n",
    "\n",
    "Usage: this class implements a basic biased matrix factorization recommender (SGD) used later in the notebook to train, evaluate, and produce recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2598143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2. Matrix Factorization\n",
    "# =========================\n",
    "\n",
    "class MatrixFactorization:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        n_factors: int = 20,\n",
    "        lr: float = 0.01,\n",
    "        reg: float = 0.1,\n",
    "        n_epochs: int = 10,\n",
    "        seed: int = 42\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Basic MF model: R ~ P @ Q^T with user/item biases.\n",
    "        \"\"\"\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.n_factors = n_factors\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.n_epochs = n_epochs\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        # Latent factors\n",
    "        self.P = 0.1 * self.rng.standard_normal((num_users, n_factors))\n",
    "        self.Q = 0.1 * self.rng.standard_normal((num_items, n_factors))\n",
    "\n",
    "        # Bias terms\n",
    "        self.user_bias = np.zeros(num_users)\n",
    "        self.item_bias = np.zeros(num_items)\n",
    "        self.global_mean = 0.0\n",
    "\n",
    "    def fit(self, train_data: np.ndarray, verbose: bool = True):\n",
    "        \"\"\"\n",
    "        Train using SGD.\n",
    "        train_data: array of shape (N, 3) with columns [user_idx, item_idx, rating].\n",
    "        \"\"\"\n",
    "        self.global_mean = train_data[:, 2].mean()\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            self.rng.shuffle(train_data)\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "            for u_idx, i_idx, r in train_data:\n",
    "                u = int(u_idx)\n",
    "                i = int(i_idx)\n",
    "                r = float(r)\n",
    "\n",
    "                pred = self.predict_single(u, i)\n",
    "                err = r - pred\n",
    "\n",
    "                pu = self.P[u, :].copy()\n",
    "                qi = self.Q[i, :].copy()\n",
    "\n",
    "                # Bias updates\n",
    "                self.user_bias[u] += self.lr * (err - self.reg * self.user_bias[u])\n",
    "                self.item_bias[i] += self.lr * (err - self.reg * self.item_bias[i])\n",
    "\n",
    "                # Latent factor updates\n",
    "                self.P[u, :] += self.lr * (err * qi - self.reg * pu)\n",
    "                self.Q[i, :] += self.lr * (err * pu - self.reg * qi)\n",
    "\n",
    "                epoch_loss += err ** 2\n",
    "\n",
    "            rmse_val = np.sqrt(epoch_loss / len(train_data))\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch + 1}/{self.n_epochs}, RMSE (train): {rmse_val:.4f}\")\n",
    "\n",
    "    def predict_single(self, user_idx: int, item_idx: int) -> float:\n",
    "        \"\"\"\n",
    "        Predict rating for a single (user, item) pair.\n",
    "        \"\"\"\n",
    "        pred = (\n",
    "            self.global_mean\n",
    "            + self.user_bias[user_idx]\n",
    "            + self.item_bias[item_idx]\n",
    "            + np.dot(self.P[user_idx, :], self.Q[item_idx, :])\n",
    "        )\n",
    "        return float(pred)\n",
    "\n",
    "    def predict_batch(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict ratings for an array of [user_idx, item_idx, rating] triplets.\n",
    "        (rating column is ignored)\n",
    "        \"\"\"\n",
    "        preds = np.zeros(len(data), dtype=float)\n",
    "        for idx, (u_idx, i_idx, _) in enumerate(data):\n",
    "            preds[idx] = self.predict_single(int(u_idx), int(i_idx))\n",
    "        return preds\n",
    "\n",
    "    def recommend_for_user(\n",
    "        self,\n",
    "        user_idx: int,\n",
    "        known_item_indices: List[int],\n",
    "        top_n: int = 10\n",
    "    ) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        Recommend top_n new items for user_idx.\n",
    "        known_item_indices: items the user already interacted with (to exclude).\n",
    "        Returns list of (item_idx, predicted_rating) sorted by rating desc.\n",
    "        \"\"\"\n",
    "        all_items = np.arange(self.num_items)\n",
    "        mask = np.ones(self.num_items, dtype=bool)\n",
    "        mask[known_item_indices] = False\n",
    "        candidate_items = all_items[mask]\n",
    "\n",
    "        scores: List[Tuple[int, float]] = []\n",
    "        for i in candidate_items:\n",
    "            scores.append((i, self.predict_single(user_idx, i)))\n",
    "\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scores[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04cd85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3. Evaluation helper\n",
    "# =========================\n",
    "\n",
    "def rmse(model: MatrixFactorization, test_data: np.ndarray) -> float:\n",
    "    preds = model.predict_batch(test_data)\n",
    "    true = test_data[:, 2].astype(float)\n",
    "    mse = np.mean((true - preds) ** 2)\n",
    "    return float(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1749a467",
   "metadata": {},
   "source": [
    "### Load interactions and then encode the ids\n",
    "\n",
    "This cell performs the following steps:\n",
    "\n",
    "- Build file paths relative to this notebook to locate `user_games.json` and an optional `game_overview` metadata file.\n",
    "- Check that `user_games.json` exists and raise an error if missing (so the notebook fails fast).\n",
    "- Load interactions using `load_user_game_ratings(path)` which returns a DataFrame with `user_id`, `game_id`, and `rating`, and prints the number of loaded rows.\n",
    "- Encode original ids into compact integer indices by calling `encode_ids(df)`, which returns `df_encoded` plus the mapping dicts (`user_id_to_idx`, `idx_to_user_id`, `game_id_to_idx`, `idx_to_game_id`).\n",
    "- Compute and print `num_users` and `num_items` from the mapping dictionaries; these values are used later to initialize the MF model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1749a467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded interactions: 257342\n",
      "Num users: 10000, Num items: 22283\n"
     ]
    }
   ],
   "source": [
    "# --- Build paths relative to THIS FOLDER (where the script lives) ---\n",
    "\n",
    "# Expect user_games.json and (optionally) game_overview.json in the same folder\n",
    "user_games_path = Path(\"..\") / \"data\" / \"json\" / \"user_games.json\"\n",
    "game_overview_path = Path(\"..\") / \"data\" / \"json\" / \"game_overview_final_vol2.json\"\n",
    "\n",
    "# 1) Load interactions\n",
    "if not user_games_path.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        f\"user_games.json not found at {user_games_path}. \"\n",
    "        f\"Put user_games.json in the same folder as this script.\"\n",
    "    )\n",
    "\n",
    "df = load_user_game_ratings(str(user_games_path))\n",
    "print(\"Loaded interactions:\", len(df))\n",
    "\n",
    "# 2) Encode ids\n",
    "(\n",
    "    df_encoded,\n",
    "    user_id_to_idx,\n",
    "    idx_to_user_id,\n",
    "    game_id_to_idx,\n",
    "    idx_to_game_id,\n",
    ") = encode_ids(df)\n",
    "\n",
    "num_users = len(user_id_to_idx)\n",
    "num_items = len(game_id_to_idx)\n",
    "print(f\"Num users: {num_users}, Num items: {num_items}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2dd43",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30776a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interactions: 205874, Test interactions: 51468\n"
     ]
    }
   ],
   "source": [
    "# 3) Train/test split\n",
    "train_data, test_data = train_test_split_interactions(df_encoded, test_ratio=0.2)\n",
    "print(f\"Train interactions: {len(train_data)}, Test interactions: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f4848",
   "metadata": {},
   "source": [
    "### Load game metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9c36c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded game_overview.json for metadata.\n"
     ]
    }
   ],
   "source": [
    "# 4) Load game metadata (optional)\n",
    "if game_overview_path.is_file():\n",
    "    game_meta_df = load_game_metadata(str(game_overview_path))\n",
    "    game_meta_dict = game_meta_df.set_index(\"game_id\").to_dict(orient=\"index\")\n",
    "    print(\"Loaded game_overview.json for metadata.\")\n",
    "else:\n",
    "    game_meta_dict = {}\n",
    "    print(\"Warning: game_overview.json not found in this folder.\")\n",
    "    print(\"Recommendations will only show game_id and predicted_rating.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe931b",
   "metadata": {},
   "source": [
    "### Train and evaluate the MF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73caedfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, RMSE (train): 0.7574\n",
      "Epoch 2/10, RMSE (train): 0.7406\n",
      "Epoch 2/10, RMSE (train): 0.7406\n",
      "Epoch 3/10, RMSE (train): 0.7272\n",
      "Epoch 3/10, RMSE (train): 0.7272\n",
      "Epoch 4/10, RMSE (train): 0.7159\n",
      "Epoch 4/10, RMSE (train): 0.7159\n",
      "Epoch 5/10, RMSE (train): 0.7062\n",
      "Epoch 5/10, RMSE (train): 0.7062\n",
      "Epoch 6/10, RMSE (train): 0.6976\n",
      "Epoch 6/10, RMSE (train): 0.6976\n",
      "Epoch 7/10, RMSE (train): 0.6897\n",
      "Epoch 7/10, RMSE (train): 0.6897\n",
      "Epoch 8/10, RMSE (train): 0.6825\n",
      "Epoch 8/10, RMSE (train): 0.6825\n",
      "Epoch 9/10, RMSE (train): 0.6757\n",
      "Epoch 9/10, RMSE (train): 0.6757\n",
      "Epoch 10/10, RMSE (train): 0.6693\n",
      "Epoch 10/10, RMSE (train): 0.6693\n",
      "Test RMSE: 0.7779\n",
      "Test RMSE: 0.7779\n"
     ]
    }
   ],
   "source": [
    "# 5) Train the MF model\n",
    "model = MatrixFactorization(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    n_factors=40,\n",
    "    lr=0.01,\n",
    "    reg=0.05,\n",
    "    n_epochs=10,\n",
    ")\n",
    "model.fit(train_data, verbose=True)\n",
    "\n",
    "# 6) Evaluate\n",
    "test_rmse_val = rmse(model, test_data)\n",
    "print(f\"Test RMSE: {test_rmse_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e7d1c",
   "metadata": {},
   "source": [
    "### Generate recommendations for ALL user\n",
    "\n",
    "This cell computes recommendations for every user in the dataset:\n",
    "\n",
    "- Precompute `user_items`: a mapping from each `user_idx` to the list of `item_idx` they have already interacted with (used to exclude seen items).\n",
    "- For each user, call `model.recommend_for_user(user_idx, known_item_indices, top_n=10)` to get top-N unseen item indices and predicted scores.\n",
    "- Look up each recommended `item_idx` in `idx_to_game_id` and (optionally) `game_meta_dict` to attach human-friendly metadata (`name`, `genres`, `platforms`, `steam_rating`, `first_release_date`).\n",
    "- Append a dict per recommendation to `all_rows` with `user_id`, `game_id`, `name`, `predicted_rating`, and metadata fields.\n",
    "- The resulting `all_rows` list is later converted to a DataFrame and saved to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed0f2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Precompute which items each user has already interacted with\n",
    "user_items = (\n",
    "    df_encoded.groupby(\"user_idx\")[\"item_idx\"].apply(list).to_dict()\n",
    ")\n",
    "\n",
    "# 8) Generate recommendations for ALL users\n",
    "all_rows = []\n",
    "\n",
    "for user_idx, user_id in idx_to_user_id.items():\n",
    "    known_items = user_items.get(user_idx, [])\n",
    "    recs = model.recommend_for_user(\n",
    "        user_idx=user_idx,\n",
    "        known_item_indices=known_items,\n",
    "        top_n=10,\n",
    "    )\n",
    "\n",
    "    for item_idx, score in recs:\n",
    "        game_id = idx_to_game_id[item_idx]\n",
    "        meta = game_meta_dict.get(game_id, {})\n",
    "        name = meta.get(\"name\", \"<unknown>\")\n",
    "        genres = meta.get(\"genres\", \"\")\n",
    "        platforms = meta.get(\"platforms\", \"\")\n",
    "        steam_rating = meta.get(\"steam_rating\", None)\n",
    "        release_date = meta.get(\"first_release_date\", None)\n",
    "\n",
    "        all_rows.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"game_id\": game_id,\n",
    "            \"name\": name,\n",
    "            \"predicted_rating\": score,\n",
    "            \"steam_rating\": steam_rating,\n",
    "            \"genres\": genres,\n",
    "            \"platforms\": platforms,\n",
    "            \"first_release_date\": release_date,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87f905",
   "metadata": {},
   "source": [
    "### Save and clean the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83dfafd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved recommendations for all users to: ..\\data\\collaborative_filtering_output.csv\n",
      "Original rows: 100000\n",
      "Rows after removing '<unknown>': 40062\n",
      "Original rows: 100000\n",
      "Rows after removing '<unknown>': 40062\n",
      "Cleaned file saved to: ..\\data\\collaborative_filtering_output_clean.csv\n",
      "Cleaned file saved to: ..\\data\\collaborative_filtering_output_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# 9) Save all users' recommendations to CSV\n",
    "all_df = pd.DataFrame(all_rows)\n",
    "output_path = Path(\"../data\") / \"collaborative_filtering_output.csv\"\n",
    "all_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved recommendations for all users to: {output_path}\")\n",
    "\n",
    "input_path = Path(\"../data\") / \"collaborative_filtering_output.csv\"\n",
    "output_path = Path(\"../data\") / \"collaborative_filtering_output_clean.csv\"\n",
    "\n",
    "if not input_path.is_file():\n",
    "    raise FileNotFoundError(f\"Input file not found: {input_path}\")\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "if \"name\" not in df.columns:\n",
    "    raise KeyError(\n",
    "        \"Column 'name' not found in the CSV. \"\n",
    "        \"Check the column names in your file.\"\n",
    "    )\n",
    "\n",
    "# Keep only rows where name is not '<unknown>' and not empty/NaN\n",
    "mask = (df[\"name\"].notna()) & (df[\"name\"].astype(str).str.strip() != \"<unknown>\")\n",
    "df_clean = df[mask].copy()\n",
    "\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"Rows after removing '<unknown>': {len(df_clean)}\")\n",
    "\n",
    "# Save cleaned CSV\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned file saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
