{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d7f7e6",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13958327",
   "metadata": {},
   "source": [
    "In this notebook we collect all the data and format the initial version of the JSON files.\n",
    "We then create a mock user database with some user-game interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3a02b",
   "metadata": {},
   "source": [
    "### Creation of API authentication caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitch API credentials\n",
    "CLIENT_ID = \"client-id\"\n",
    "CLIENT_SECRET = \"client-secret\"\n",
    "\n",
    "TOKEN_URL = \"https://id.twitch.tv/oauth2/token\"\n",
    "\n",
    "def get_auth_header():\n",
    "    print(\"Requesting OAuth token from Twitch...\")\n",
    "    token_resp = requests.post(\n",
    "        TOKEN_URL,\n",
    "        params={\n",
    "            \"client_id\": CLIENT_ID,\n",
    "            \"client_secret\": CLIENT_SECRET,\n",
    "            \"grant_type\": \"client_credentials\",\n",
    "        },\n",
    "    )\n",
    "    token_resp.raise_for_status()\n",
    "    token_data = token_resp.json()\n",
    "    access_token = token_data[\"access_token\"]\n",
    "    print(\"Got access token.\")\n",
    "\n",
    "    headers = {\n",
    "        \"Client-ID\": CLIENT_ID,\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "    }\n",
    "\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295bf46",
   "metadata": {},
   "source": [
    "### Call to fetch the games in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28181e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGDB_GAMES_URL = \"https://api.igdb.com/v4/games\"\n",
    "\n",
    "# Folder for raw data\n",
    "RAW_DIR = Path(\"./data/raw\")\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "headers = get_auth_header()\n",
    "\n",
    "all_games = []\n",
    "batch_size = 500\n",
    "offset = 0\n",
    "\n",
    "while True:\n",
    "    print(f\"Requesting games: offset={offset}, limit={batch_size}...\")\n",
    "    query = f\"\"\"\n",
    "    fields id, name, summary, first_release_date, genres, platforms, keywords, involved_companies;\n",
    "    where first_release_date != null;\n",
    "    limit {batch_size};\n",
    "    offset {offset};\n",
    "    \"\"\"\n",
    "\n",
    "    resp = requests.post(IGDB_GAMES_URL, headers=headers, data=query)\n",
    "    resp.raise_for_status()\n",
    "    batch = resp.json()\n",
    "    print(f\"Got {len(batch)} games in this batch\")\n",
    "\n",
    "    if not batch:\n",
    "        print(\"No more games, stopping.\")\n",
    "        break\n",
    "\n",
    "    all_games.extend(batch)\n",
    "\n",
    "    # move to next page\n",
    "    offset += batch_size\n",
    "\n",
    "    # optional: stop at some max\n",
    "    # if offset >= 5000:\n",
    "    #     break\n",
    "\n",
    "print(f\"Total games collected: {len(all_games)}\")\n",
    "\n",
    "out_file = RAW_DIR / \"games_raw.json\"\n",
    "with out_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_games, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved all games to {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353ac27",
   "metadata": {},
   "source": [
    "### Format JSON files and add Steam IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = Path(\"./data/raw\")\n",
    "JSON_DIR = Path(\"./data/json\")\n",
    "JSON_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "headers = get_auth_header()\n",
    "\n",
    "IGDB_GENRES_URL = \"https://api.igdb.com/v4/genres\"\n",
    "IGDB_PLATFORMS_URL = \"https://api.igdb.com/v4/platforms\"\n",
    "IGDB_KEYWORDS_URL = \"https://api.igdb.com/v4/keywords\"\n",
    "IGDB_INVOLVED_URL = \"https://api.igdb.com/v4/involved_companies\"\n",
    "IGDB_COMPANIES_URL = \"https://api.igdb.com/v4/companies\"\n",
    "IGDB_EXTERNAL_GAMES_URL = \"https://api.igdb.com/v4/external_games\"\n",
    "STEAM_CATEGORY_ID = 1  # IGDB enum value for Steam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_steam_ids_for_games(game_ids):\n",
    "    \"\"\"\n",
    "    Return a dict: { game_id (IGDB) -> steam_appid (string) }\n",
    "    using IGDB's external_games endpoint, filtering category=Steam.\n",
    "    \"\"\"\n",
    "    if not game_ids:\n",
    "        return {}\n",
    "\n",
    "    game_ids_list = sorted(list(game_ids))\n",
    "    chunk_size = 500  # IGDB limit per request\n",
    "    mapping = {}\n",
    "\n",
    "    for i in range(0, len(game_ids_list), chunk_size):\n",
    "        chunk = game_ids_list[i:i + chunk_size]\n",
    "        ids_str = \",\".join(str(gid) for gid in chunk)\n",
    "\n",
    "        body = f\"\"\"\n",
    "        fields game, uid, category;\n",
    "        where game = ({ids_str}) & category = {STEAM_CATEGORY_ID};\n",
    "        limit 500;\n",
    "        \"\"\"\n",
    "\n",
    "        resp = requests.post(IGDB_EXTERNAL_GAMES_URL, headers=headers, data=body)\n",
    "        resp.raise_for_status()\n",
    "        items = resp.json()\n",
    "\n",
    "        for item in items:\n",
    "            game_id = item[\"game\"]\n",
    "            steam_uid = item[\"uid\"]   # Steam appid as string/number\n",
    "            # In case of multiple external entries per game, keep the first\n",
    "            if game_id not in mapping:\n",
    "                mapping[game_id] = str(steam_uid)\n",
    "\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de382ab4",
   "metadata": {},
   "source": [
    "We load the raw games data collected earlier to extract Steam IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_file = RAW_DIR / \"games_raw.json\"\n",
    "with games_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    games = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(games)} games from {games_file}\")\n",
    "\n",
    "# collect all IGDB game_ids from raw games\n",
    "game_ids_set = {g[\"id\"] for g in games}\n",
    "\n",
    "print(\"Fetching Steam appids from IGDB external_games...\")\n",
    "steam_ids_map = fetch_steam_ids_for_games(game_ids_set)\n",
    "print(f\"Found Steam appids for {len(steam_ids_map)} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d8791",
   "metadata": {},
   "source": [
    "Now we enrich games with steam_appid where available and start giving a format to the end JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_games = []\n",
    "rows_game_genres = []\n",
    "rows_game_platforms = []\n",
    "rows_game_keywords = []\n",
    "rows_game_companies = []\n",
    "\n",
    "genre_ids_set = set()\n",
    "platform_ids_set = set()\n",
    "keyword_ids_set = set()\n",
    "involved_company_ids_set = set()\n",
    "company_ids_set = set()\n",
    "\n",
    "for g in games:\n",
    "    game_id = g[\"id\"]  # use IGDB id as our game_id\n",
    "\n",
    "    rows_games.append({\n",
    "        \"game_id\": game_id,\n",
    "        \"igdb_id\": g[\"id\"],\n",
    "        \"name\": g.get(\"name\"),\n",
    "        \"summary\": g.get(\"summary\"),\n",
    "        \"first_release_date\": g.get(\"first_release_date\"),\n",
    "        \"steam_appid\": steam_ids_map.get(game_id),\n",
    "    })\n",
    "\n",
    "    # genres\n",
    "    for genre_id in g.get(\"genres\", []):\n",
    "        rows_game_genres.append({\n",
    "            \"game_id\": game_id,\n",
    "            \"genre_id\": genre_id,\n",
    "        })\n",
    "        genre_ids_set.add(genre_id)\n",
    "\n",
    "    # platforms\n",
    "    for platform_id in g.get(\"platforms\", []):\n",
    "        rows_game_platforms.append({\n",
    "            \"game_id\": game_id,\n",
    "            \"platform_id\": platform_id,\n",
    "        })\n",
    "        platform_ids_set.add(platform_id)\n",
    "\n",
    "    # keywords\n",
    "    for keyword_id in g.get(\"keywords\", []):\n",
    "        rows_game_keywords.append({\n",
    "            \"game_id\": game_id,\n",
    "            \"keyword_id\": keyword_id,\n",
    "        })\n",
    "        keyword_ids_set.add(keyword_id)\n",
    "\n",
    "    # involved_companies\n",
    "    for inv_id in g.get(\"involved_companies\", []):\n",
    "        # we only know the involved_company ID for now\n",
    "        rows_game_companies.append({\n",
    "            \"game_id\": game_id,\n",
    "            \"involved_company_id\": inv_id,\n",
    "        })\n",
    "        involved_company_ids_set.add(inv_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = pd.DataFrame(rows_games)\n",
    "df_game_genres = pd.DataFrame(rows_game_genres)\n",
    "df_game_platforms = pd.DataFrame(rows_game_platforms)\n",
    "\n",
    "df_game_keywords = pd.DataFrame(rows_game_keywords)\n",
    "df_game_companies = pd.DataFrame(rows_game_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ba9fd",
   "metadata": {},
   "source": [
    "We resolve genre and platform names next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_lookup_table(url, ids, id_field=\"id\", name_field=\"name\", chunk_size=500):\n",
    "    \"\"\"Fetch id->name mapping (genres, platforms, keywords, companies) from IGDB in chunks.\"\"\"\n",
    "    if not ids:\n",
    "        return pd.DataFrame(columns=[id_field, name_field])\n",
    "\n",
    "    ids_list = sorted(list(ids))\n",
    "    frames = []\n",
    "\n",
    "    for start in range(0, len(ids_list), chunk_size):\n",
    "        chunk = ids_list[start:start + chunk_size]\n",
    "        ids_str = \",\".join(str(i) for i in chunk)\n",
    "\n",
    "        body = f\"\"\"\n",
    "        fields {id_field}, {name_field};\n",
    "        where id = ({ids_str});\n",
    "        limit {len(chunk)};\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Fetching lookup from {url}: {start}–{start + len(chunk)} of {len(ids_list)}\")\n",
    "        resp = requests.post(url, headers=headers, data=body)\n",
    "\n",
    "        if resp.status_code != 200:\n",
    "            print(\"Error response:\", resp.status_code, resp.text[:300])\n",
    "            resp.raise_for_status()\n",
    "\n",
    "        items = resp.json()\n",
    "        if items:\n",
    "            df_chunk = pd.DataFrame(items)[[id_field, name_field]]\n",
    "            frames.append(df_chunk)\n",
    "\n",
    "        # short delay to avoid hammering the API\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    if frames:\n",
    "        df = pd.concat(frames, ignore_index=True)\n",
    "        df = df.drop_duplicates(subset=[id_field])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=[id_field, name_field])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b214fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_involved_companies(ids, chunk_size=200):\n",
    "    \"\"\"\n",
    "    Fetch involved_companies rows from IGDB in chunks to avoid 413 / payload too large.\n",
    "    Returns a DataFrame with columns:\n",
    "    id, company, game, developer, publisher, porting, supporting\n",
    "    \"\"\"\n",
    "    if not ids:\n",
    "        return pd.DataFrame(columns=[\"id\", \"company\", \"game\", \"developer\", \"publisher\", \"porting\", \"supporting\"])\n",
    "\n",
    "    ids_list = sorted(list(ids))\n",
    "    frames = []\n",
    "\n",
    "    for start in range(0, len(ids_list), chunk_size):\n",
    "        chunk = ids_list[start:start + chunk_size]\n",
    "        ids_str = \",\".join(str(i) for i in chunk)\n",
    "\n",
    "        body = f\"\"\"\n",
    "        fields id, company, game, developer, publisher, porting, supporting;\n",
    "        where id = ({ids_str});\n",
    "        limit {len(chunk)};\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Fetching involved_companies: {start}–{start + len(chunk)} of {len(ids_list)}\")\n",
    "        resp = requests.post(IGDB_INVOLVED_URL, headers=headers, data=body)\n",
    "\n",
    "        if resp.status_code != 200:\n",
    "            print(\"Error response from involved_companies:\", resp.status_code, resp.text[:300])\n",
    "            resp.raise_for_status()\n",
    "\n",
    "        items = resp.json()\n",
    "        if items:\n",
    "            df_chunk = pd.DataFrame(items)\n",
    "            frames.append(df_chunk)\n",
    "\n",
    "        # be nice to IGDB\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    if frames:\n",
    "        df = pd.concat(frames, ignore_index=True)\n",
    "        df = df.drop_duplicates(subset=[\"id\"])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=[\"id\", \"company\", \"game\", \"developer\", \"publisher\", \"porting\", \"supporting\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre lookup\n",
    "df_genres = fetch_lookup_table(IGDB_GENRES_URL, genre_ids_set, id_field=\"id\", name_field=\"name\")\n",
    "df_genres = df_genres.rename(columns={\"id\": \"genre_id\"})\n",
    "\n",
    "# platform lookup\n",
    "df_platforms = fetch_lookup_table(IGDB_PLATFORMS_URL, platform_ids_set, id_field=\"id\", name_field=\"name\")\n",
    "df_platforms = df_platforms.rename(columns={\"id\": \"platform_id\"})\n",
    "\n",
    "# keyword lookup\n",
    "df_keywords = fetch_lookup_table(IGDB_KEYWORDS_URL, keyword_ids_set, id_field=\"id\", name_field=\"name\")\n",
    "df_keywords = df_keywords.rename(columns={\"id\": \"keyword_id\"})\n",
    "\n",
    "df_involved = fetch_involved_companies(involved_company_ids_set)\n",
    "\n",
    "# collect company IDs from here\n",
    "if not df_involved.empty:\n",
    "    company_ids_set = set(df_involved[\"company\"].tolist())\n",
    "else:\n",
    "    company_ids_set = set()\n",
    "\n",
    "df_companies = fetch_lookup_table(IGDB_COMPANIES_URL, company_ids_set, id_field=\"id\", name_field=\"name\")\n",
    "df_companies = df_companies.rename(columns={\"id\": \"company_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf672ae",
   "metadata": {},
   "source": [
    "We save all the JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8208903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_as_json(df, path):\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "save_df_as_json(df_games, JSON_DIR / \"games.json\")\n",
    "save_df_as_json(df_game_genres, JSON_DIR / \"game_genres.json\")\n",
    "save_df_as_json(df_game_platforms, JSON_DIR / \"game_platforms.json\")\n",
    "save_df_as_json(df_genres, JSON_DIR / \"genres.json\")\n",
    "save_df_as_json(df_platforms, JSON_DIR / \"platforms.json\")\n",
    "\n",
    "save_df_as_json(df_game_keywords, JSON_DIR / \"game_keywords.json\")\n",
    "save_df_as_json(df_keywords, JSON_DIR / \"keywords.json\")\n",
    "save_df_as_json(df_game_companies, JSON_DIR / \"game_involved_companies.json\")\n",
    "save_df_as_json(df_involved, JSON_DIR / \"involved_companies_raw.json\")\n",
    "save_df_as_json(df_companies, JSON_DIR / \"companies.json\")\n",
    "\n",
    "print(\"Saved JSON files to\", JSON_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69448e2",
   "metadata": {},
   "source": [
    "### Fetching of the Steam reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b07f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMES_FILE = JSON_DIR / \"games.json\"\n",
    "OUT_FILE = JSON_DIR / \"steam_reviews.json\"\n",
    "\n",
    "STEAM_REVIEW_URL = (\n",
    "    \"https://store.steampowered.com/appreviews/{appid}\"\n",
    "    \"?json=1&language=all&purchase_type=all&num_per_page=0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb88cdc",
   "metadata": {},
   "source": [
    "Load the games from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b69789",
   "metadata": {},
   "outputs": [],
   "source": [
    "with GAMES_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    games = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a2c88",
   "metadata": {},
   "source": [
    "Get the games with Steam ID and look for their reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_reviews = []\n",
    "\n",
    "for g in games:\n",
    "    appid = g.get(\"steam_appid\")\n",
    "    game_id = g[\"game_id\"]\n",
    "\n",
    "    if not appid:\n",
    "        continue  # skip games without steam mapping\n",
    "\n",
    "    url = STEAM_REVIEW_URL.format(appid=appid)\n",
    "    print(f\"Fetching reviews for game_id={game_id}, appid={appid} ...\")\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        summary = data.get(\"query_summary\", {})\n",
    "        rows_reviews.append({\n",
    "            \"game_id\": game_id,\n",
    "            \"steam_appid\": appid,\n",
    "            \"total_positive\": summary.get(\"total_positive\", 0),\n",
    "            \"total_negative\": summary.get(\"total_negative\", 0),\n",
    "            \"total_reviews\": summary.get(\"total_reviews\", 0),\n",
    "        })\n",
    "\n",
    "        # small delay to be polite\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error for appid={appid}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3d525",
   "metadata": {},
   "source": [
    "Save into JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe21f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with OUT_FILE.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(rows_reviews, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved Steam review stats to {OUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476cddb",
   "metadata": {},
   "source": [
    "### Generation of the mock users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd03a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERS_OUT_FILE = JSON_DIR / \"users.json\"\n",
    "USER_GAMES_OUT_FILE = JSON_DIR / \"user_games.json\"\n",
    "\n",
    "N_USERS = 10000\n",
    "MIN_GAMES_PER_USER = 1\n",
    "MAX_GAMES_PER_USER = 50\n",
    "\n",
    "# some random countries to add more stuff\n",
    "COUNTRIES = [\"US\", \"GB\", \"DE\", \"FR\", \"ES\", \"IT\", \"BR\", \"CA\", \"AU\", \"JP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a9c50",
   "metadata": {},
   "source": [
    "Load the games file and filter for those with Steam ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with GAMES_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    games = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(games)} games from {GAMES_FILE}\")\n",
    "\n",
    "# Filter to games that have a steam_appid\n",
    "games_with_appid = [g for g in games if g.get(\"steam_appid\")]\n",
    "if games_with_appid:\n",
    "    games = games_with_appid\n",
    "    print(f\"Using {len(games)} games that have a Steam appid\")\n",
    "\n",
    "if not games:\n",
    "    raise RuntimeError(\"No games available to generate interactions!\")\n",
    "\n",
    "game_ids = [g[\"game_id\"] for g in games]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d83b5",
   "metadata": {},
   "source": [
    "Generate the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user(user_id: int) -> dict:\n",
    "    username = f\"user_{user_id}\"\n",
    "    country = random.choice(COUNTRIES)\n",
    "    age = random.randint(16, 45)  # arbitrary range\n",
    "\n",
    "    return {\n",
    "        \"user_id\": user_id,\n",
    "        \"username\": username,\n",
    "        \"country\": country,\n",
    "        \"age\": age,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41851579",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [generate_user(i) for i in range(1, N_USERS + 1)]\n",
    "print(f\"Generated {len(users)} mock users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f895b7",
   "metadata": {},
   "source": [
    "Generate user-game interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861302d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_games(user_id: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Generate a random list of interactions for a single user.\n",
    "    Each interaction has: user_id, game_id, rating, playtime_hours.\n",
    "    \"\"\"\n",
    "    n_games = random.randint(MIN_GAMES_PER_USER, MAX_GAMES_PER_USER)\n",
    "    # sample without replacement so each user doesn't repeat the same game\n",
    "    sampled_game_ids = random.sample(game_ids, k=min(n_games, len(game_ids)))\n",
    "\n",
    "    interactions = []\n",
    "    for gid in sampled_game_ids:\n",
    "        # rating: skew towards higher ratings a bit (gamers rarely rate 1/5)\n",
    "        rating = round(min(max(random.gauss(3.8, 0.8), 1.0), 5.0), 1)\n",
    "\n",
    "        # playtime: heavy-tailed – many low-play games, some very high\n",
    "        # log-normal-ish: exp of a normal\n",
    "        base = random.gauss(2.0, 1.0)\n",
    "        playtime_hours = max(0.1, round((2.71828 ** base), 1))  # e^base, clamp at 0.1\n",
    "\n",
    "        interactions.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"game_id\": gid,\n",
    "            \"rating\": rating,\n",
    "            \"playtime_hours\": playtime_hours,\n",
    "        })\n",
    "\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_games = []\n",
    "for u in users:\n",
    "    ug = generate_user_games(u[\"user_id\"])\n",
    "    user_games.extend(ug)\n",
    "\n",
    "print(f\"Generated {len(user_games)} user-game interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480f7e3",
   "metadata": {},
   "source": [
    "Save to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee428380",
   "metadata": {},
   "outputs": [],
   "source": [
    "with USERS_OUT_FILE.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(users, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with USER_GAMES_OUT_FILE.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(user_games, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved users to {USERS_OUT_FILE}\")\n",
    "print(f\"Saved user-game interactions to {USER_GAMES_OUT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videogame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
